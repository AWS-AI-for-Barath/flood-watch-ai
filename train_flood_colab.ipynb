{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FloodWatch YOLO — Max-Accuracy Training (YOLOv8m)\n",
                "\n",
                "Train YOLOv8m at 832px for 200 epochs on the normalized flood dataset.\n",
                "\n",
                "| Setting | Value |\n",
                "|---------|-------|\n",
                "| Model | YOLOv8m (25.9M params) |\n",
                "| Resolution | 832px |\n",
                "| Epochs | 200 (patience=40) |\n",
                "| Optimizer | AdamW lr=0.002 |\n",
                "| Box loss | 7.5 (CIoU) |\n",
                "| Target | mAP50 ≥ 0.80–0.85 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1️⃣ Setup & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q ultralytics roboflow Pillow\n",
                "\n",
                "import os, glob, shutil, json\n",
                "from collections import Counter, defaultdict\n",
                "from ultralytics import YOLO\n",
                "\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    vram = torch.cuda.get_device_properties(0).total_mem / 1e9\n",
                "    print(f'GPU: {torch.cuda.get_device_name(0)} ({vram:.1f} GB)')\n",
                "else:\n",
                "    print('WARNING: No GPU detected!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2️⃣ Download Flood Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from roboflow import Roboflow\n",
                "\n",
                "# Enter your Roboflow API key\n",
                "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
                "project = rf.workspace().project(\"flood-detection-oelzf\")\n",
                "version = project.version(1)\n",
                "dataset = version.download(\"yolov8\", location=\"./flood_dataset\")\n",
                "print('Dataset downloaded!')\n",
                "\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    imgs = glob.glob(f'./flood_dataset/{split}/images/*')\n",
                "    print(f'  {split}: {len(imgs)} images')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3️⃣ Normalize Labels (Polygon → BBox)\n",
                "\n",
                "**Critical:** Roboflow exports segmentation polygons. YOLO detect needs `class xc yc w h`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def polygon_to_bbox(parts):\n",
                "    if len(parts) < 5: return None\n",
                "    try:\n",
                "        cls_id = int(parts[0])\n",
                "        coords = [float(v) for v in parts[1:]]\n",
                "    except (ValueError, IndexError): return None\n",
                "    if len(coords) % 2 != 0: return None\n",
                "    xs, ys = coords[0::2], coords[1::2]\n",
                "    if not xs or not ys: return None\n",
                "    x_min, x_max = max(0, min(xs)), min(1, max(xs))\n",
                "    y_min, y_max = max(0, min(ys)), min(1, max(ys))\n",
                "    w, h = x_max - x_min, y_max - y_min\n",
                "    if w <= 0 or h <= 0: return None\n",
                "    return f'{cls_id} {x_min+w/2:.6f} {y_min+h/2:.6f} {w:.6f} {h:.6f}'\n",
                "\n",
                "poly_count = 0\n",
                "bbox_count = 0\n",
                "files_fixed = 0\n",
                "\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    lbl_dir = f'./flood_dataset/{split}/labels'\n",
                "    if not os.path.isdir(lbl_dir): continue\n",
                "    for fname in sorted(os.listdir(lbl_dir)):\n",
                "        if not fname.endswith('.txt'): continue\n",
                "        fpath = os.path.join(lbl_dir, fname)\n",
                "        with open(fpath) as f:\n",
                "            lines = f.readlines()\n",
                "        converted = []\n",
                "        had_poly = False\n",
                "        for line in lines:\n",
                "            parts = line.strip().split()\n",
                "            if len(parts) == 5:\n",
                "                converted.append(line.strip())\n",
                "                bbox_count += 1\n",
                "            elif len(parts) > 5:\n",
                "                b = polygon_to_bbox(parts)\n",
                "                if b:\n",
                "                    converted.append(b)\n",
                "                    poly_count += 1\n",
                "                    had_poly = True\n",
                "        if had_poly:\n",
                "            with open(fpath, 'w') as f:\n",
                "                f.write('\\n'.join(converted) + '\\n')\n",
                "            files_fixed += 1\n",
                "\n",
                "print(f'Polygons converted: {poly_count}')\n",
                "print(f'Already bbox: {bbox_count}')\n",
                "print(f'Files fixed: {files_fixed}')\n",
                "print('✅ All labels normalized to detection format!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4️⃣ Audit & Clean Labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "VALID_CLS = {0, 1, 2, 3, 4, 5}\n",
                "MIN_AREA = 0.001\n",
                "DUP_IOU = 0.95\n",
                "\n",
                "def iou(b1, b2):\n",
                "    _, x1, y1, w1, h1 = b1\n",
                "    _, x2, y2, w2, h2 = b2\n",
                "    ax1, ay1, ax2, ay2 = x1-w1/2, y1-h1/2, x1+w1/2, y1+h1/2\n",
                "    bx1, by1, bx2, by2 = x2-w2/2, y2-h2/2, x2+w2/2, y2+h2/2\n",
                "    ix1, iy1 = max(ax1,bx1), max(ay1,by1)\n",
                "    ix2, iy2 = min(ax2,bx2), min(ay2,by2)\n",
                "    if ix2<=ix1 or iy2<=iy1: return 0.0\n",
                "    inter = (ix2-ix1)*(iy2-iy1)\n",
                "    union = w1*h1 + w2*h2 - inter\n",
                "    return inter / union if union > 0 else 0.0\n",
                "\n",
                "stats = defaultdict(int)\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    lbl_dir = f'./flood_dataset/{split}/labels'\n",
                "    if not os.path.isdir(lbl_dir): continue\n",
                "    for fname in sorted(os.listdir(lbl_dir)):\n",
                "        if not fname.endswith('.txt'): continue\n",
                "        fpath = os.path.join(lbl_dir, fname)\n",
                "        with open(fpath) as f:\n",
                "            lines = f.readlines()\n",
                "        anns = []\n",
                "        for line in lines:\n",
                "            p = line.strip().split()\n",
                "            if len(p) < 5: continue\n",
                "            try:\n",
                "                cls = int(p[0])\n",
                "                xc, yc, w, h = float(p[1]), float(p[2]), float(p[3]), float(p[4])\n",
                "            except: continue\n",
                "            if cls not in VALID_CLS: stats['invalid_class'] += 1; continue\n",
                "            xc = max(0, min(1, xc)); yc = max(0, min(1, yc))\n",
                "            if w*h < MIN_AREA: stats['tiny'] += 1; continue\n",
                "            anns.append((cls, xc, yc, w, h))\n",
                "        final = []\n",
                "        for a in anns:\n",
                "            if any(a[0]==e[0] and iou(a,e)>DUP_IOU for e in final):\n",
                "                stats['duplicate'] += 1\n",
                "            else:\n",
                "                final.append(a)\n",
                "        if not final:\n",
                "            stats['empty'] += 1\n",
                "            os.remove(fpath)\n",
                "            for ext in ('.jpg','.jpeg','.png'):\n",
                "                img = fpath.replace('/labels/','/images/').replace('.txt', ext)\n",
                "                if os.path.isfile(img): os.remove(img); break\n",
                "            continue\n",
                "        if len(final) != len(lines):\n",
                "            with open(fpath, 'w') as f:\n",
                "                for c, xc, yc, w, h in final:\n",
                "                    f.write(f'{c} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n')\n",
                "            stats['fixed'] += 1\n",
                "\n",
                "print('Label Audit:')\n",
                "for k, v in sorted(stats.items()):\n",
                "    print(f'  {k}: {v}')\n",
                "print('✅ Labels cleaned!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5️⃣ Balance Class Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image, ImageOps\n",
                "\n",
                "NAMES = {0:'person', 1:'car', 2:'bicycle', 3:'motorcycle', 4:'bus', 5:'truck'}\n",
                "\n",
                "counts = Counter()\n",
                "cls_files = defaultdict(set)\n",
                "lbl_dir = './flood_dataset/train/labels'\n",
                "img_dir = './flood_dataset/train/images'\n",
                "\n",
                "for fname in os.listdir(lbl_dir):\n",
                "    if not fname.endswith('.txt'): continue\n",
                "    with open(os.path.join(lbl_dir, fname)) as f:\n",
                "        for line in f:\n",
                "            p = line.strip().split()\n",
                "            if len(p) >= 5:\n",
                "                c = int(p[0])\n",
                "                counts[c] += 1\n",
                "                cls_files[c].add(fname)\n",
                "\n",
                "print('Class distribution (before):')\n",
                "for c in sorted(counts):\n",
                "    print(f'  {c} ({NAMES.get(c,\"?\"):12s}): {counts[c]:5d} ann, {len(cls_files[c]):4d} imgs')\n",
                "\n",
                "if counts:\n",
                "    max_count = max(counts.values())\n",
                "    target = int(max_count * 0.7)\n",
                "    dup = 0\n",
                "    for cls_id, cnt in counts.items():\n",
                "        if cnt >= target: continue\n",
                "        files = list(cls_files.get(cls_id, []))\n",
                "        if not files: continue\n",
                "        needed = target - cnt\n",
                "        for i in range(min(needed, len(files)*3)):\n",
                "            src = files[i % len(files)]\n",
                "            base = os.path.splitext(src)[0]\n",
                "            dst_lbl = os.path.join(lbl_dir, f'{base}_dup{i}.txt')\n",
                "            if os.path.exists(dst_lbl): continue\n",
                "            shutil.copy2(os.path.join(lbl_dir, src), dst_lbl)\n",
                "            for ext in ('.jpg','.jpeg','.png'):\n",
                "                src_img = os.path.join(img_dir, base + ext)\n",
                "                if os.path.isfile(src_img):\n",
                "                    dst_img = os.path.join(img_dir, f'{base}_dup{i}{ext}')\n",
                "                    try:\n",
                "                        img = Image.open(src_img)\n",
                "                        ImageOps.mirror(img).save(dst_img)\n",
                "                        with open(dst_lbl) as f:\n",
                "                            lbls = f.readlines()\n",
                "                        flipped = []\n",
                "                        for l in lbls:\n",
                "                            p = l.strip().split()\n",
                "                            if len(p)==5:\n",
                "                                flipped.append(f'{p[0]} {1-float(p[1]):.6f} {p[2]} {p[3]} {p[4]}')\n",
                "                        with open(dst_lbl, 'w') as f:\n",
                "                            f.write('\\n'.join(flipped)+'\\n')\n",
                "                    except:\n",
                "                        shutil.copy2(src_img, dst_img)\n",
                "                    break\n",
                "            dup += 1\n",
                "    print(f'\\nOversampled {dup} images for minority classes')\n",
                "print('✅ Classes balanced!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6️⃣ Tighten Bounding Boxes\n",
                "\n",
                "Shrink loose boxes by 3% to remove auto-annotation padding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tightened = 0\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    d = f'./flood_dataset/{split}/labels'\n",
                "    if not os.path.isdir(d): continue\n",
                "    for fname in os.listdir(d):\n",
                "        if not fname.endswith('.txt'): continue\n",
                "        fpath = os.path.join(d, fname)\n",
                "        with open(fpath) as f:\n",
                "            lines = f.readlines()\n",
                "        out = []\n",
                "        for line in lines:\n",
                "            p = line.strip().split()\n",
                "            if len(p) != 5: out.append(line.strip()); continue\n",
                "            try:\n",
                "                c = int(p[0])\n",
                "                xc, yc, w, h = float(p[1]), float(p[2]), float(p[3]), float(p[4])\n",
                "                w *= 0.94; h *= 0.94\n",
                "                w = max(w, 0.01); h = max(h, 0.01)\n",
                "                xc = max(w/2, min(1-w/2, xc))\n",
                "                yc = max(h/2, min(1-h/2, yc))\n",
                "                out.append(f'{c} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}')\n",
                "                tightened += 1\n",
                "            except:\n",
                "                out.append(line.strip())\n",
                "        with open(fpath, 'w') as f:\n",
                "            f.write('\\n'.join(out) + '\\n')\n",
                "\n",
                "print(f'Tightened {tightened} bboxes')\n",
                "print('✅ Bboxes tightened!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7️⃣ Train YOLOv8m — Max-Accuracy Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_NAME = 'yolov8m.pt'\n",
                "IMG_SIZE = 832\n",
                "EPOCHS = 200\n",
                "PATIENCE = 40\n",
                "BATCH = -1  # auto-fit GPU\n",
                "\n",
                "# Use yolov8l if enough VRAM\n",
                "if torch.cuda.is_available():\n",
                "    vram = torch.cuda.get_device_properties(0).total_mem / 1e9\n",
                "    if vram >= 24:\n",
                "        MODEL_NAME = 'yolov8l.pt'\n",
                "        print(f'Large VRAM detected, using {MODEL_NAME}')\n",
                "\n",
                "print(f'Training: {MODEL_NAME} @ {IMG_SIZE}px for {EPOCHS} epochs')\n",
                "model = YOLO(MODEL_NAME)\n",
                "\n",
                "results = model.train(\n",
                "    data='./flood_dataset/data.yaml',\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH,\n",
                "    patience=PATIENCE,\n",
                "    device=0,\n",
                "    project='./runs',\n",
                "    name='flood_maxacc',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    # Optimizer\n",
                "    optimizer='AdamW',\n",
                "    lr0=0.002,\n",
                "    lrf=0.01,\n",
                "    weight_decay=0.0005,\n",
                "    warmup_epochs=5,\n",
                "    warmup_momentum=0.8,\n",
                "    cos_lr=True,\n",
                "    # Augmentations\n",
                "    mosaic=1.0,\n",
                "    mixup=0.1,\n",
                "    hsv_h=0.015,\n",
                "    hsv_s=0.7,\n",
                "    hsv_v=0.4,\n",
                "    scale=0.5,\n",
                "    translate=0.1,\n",
                "    perspective=0.0005,\n",
                "    flipud=0.2,\n",
                "    fliplr=0.5,\n",
                "    degrees=5.0,\n",
                "    shear=2.0,\n",
                "    copy_paste=0.1,\n",
                "    erasing=0.1,\n",
                "    # Loss weights (localization emphasis)\n",
                "    box=7.5,\n",
                "    cls=0.5,\n",
                "    dfl=1.5,\n",
                "    # Output\n",
                "    save=True,\n",
                "    save_period=25,\n",
                "    plots=True,\n",
                "    val=True,\n",
                "    verbose=True,\n",
                ")\n",
                "\n",
                "print('✅ Training complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8️⃣ Evaluate & Compare with Baseline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "BASELINE_MAP50 = 0.69\n",
                "\n",
                "m = results.results_dict if hasattr(results, 'results_dict') else {}\n",
                "p  = m.get('metrics/precision(B)', None)\n",
                "r  = m.get('metrics/recall(B)', None)\n",
                "m50 = m.get('metrics/mAP50(B)', None)\n",
                "m95 = m.get('metrics/mAP50-95(B)', None)\n",
                "\n",
                "print('=' * 55)\n",
                "print('  FloodWatch YOLO — Max-Accuracy Results')\n",
                "print('=' * 55)\n",
                "print(f'  Model:      {MODEL_NAME}')\n",
                "print(f'  Resolution: {IMG_SIZE}px')\n",
                "print(f'  Epochs:     {EPOCHS}')\n",
                "print()\n",
                "print(f'  Precision:  {p}')\n",
                "print(f'  Recall:     {r}')\n",
                "print(f'  mAP50:      {m50}')\n",
                "print(f'  mAP50-95:   {m95}')\n",
                "print()\n",
                "if m50 is not None:\n",
                "    delta = m50 - BASELINE_MAP50\n",
                "    status = 'IMPROVED' if delta > 0 else 'REGRESSION'\n",
                "    print(f'  Baseline mAP50: {BASELINE_MAP50:.4f}')\n",
                "    print(f'  Delta:          {delta:+.4f} ({status})')\n",
                "print('=' * 55)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9️⃣ Export Production Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "best_pt = './runs/flood_maxacc/weights/best.pt'\n",
                "export_name = 'yolov8_flood_highacc.pt'\n",
                "\n",
                "if os.path.isfile(best_pt):\n",
                "    shutil.copy2(best_pt, export_name)\n",
                "    size_mb = os.path.getsize(export_name) / 1e6\n",
                "    print(f'Exported: {export_name} ({size_mb:.1f} MB)')\n",
                "    print('Download this file and place at: models/yolov8_flood_highacc.pt')\n",
                "else:\n",
                "    print(f'best.pt not found at {best_pt}')\n",
                "\n",
                "# Also export ONNX for deployment\n",
                "try:\n",
                "    best_model = YOLO(best_pt)\n",
                "    best_model.export(format='onnx', imgsz=IMG_SIZE)\n",
                "    print('ONNX exported!')\n",
                "except Exception as e:\n",
                "    print(f'ONNX export failed: {e}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}